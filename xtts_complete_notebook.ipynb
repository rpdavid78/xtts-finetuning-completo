{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# üé§ XTTS v2 Fine-tuning Completo com Monitoramento\n",
    "\n",
    "## üéØ **Objetivo**\n",
    "Treinar um modelo de IA que se **especializa na sua voz** com qualidade dramaticamente superior (7/10 ‚Üí 9/10) e sistema completo de monitoramento visual.\n",
    "\n",
    "## üöÄ **Recursos Inclu√≠dos**\n",
    "- ‚úÖ **Setup autom√°tico** completo\n",
    "- ‚úÖ **Fine-tuning com monitoramento** em tempo real\n",
    "- ‚úÖ **Sistema de infer√™ncia** integrado\n",
    "- ‚úÖ **An√°lise de qualidade** autom√°tica\n",
    "- ‚úÖ **Interface web** opcional\n",
    "- ‚úÖ **Gr√°ficos e m√©tricas** profissionais\n",
    "\n",
    "## üíª **Requisitos M√≠nimos**\n",
    "- üî• **GPU:** RTX 3070+ com 8GB+ VRAM\n",
    "- üíæ **RAM:** 16GB+ (32GB recomendado)\n",
    "- üíø **Armazenamento:** 50GB+ livres\n",
    "- üêç **Python:** 3.8-3.11\n",
    "\n",
    "---\n",
    "\n",
    "**üìã INSTRU√á√ïES:** Execute as c√©lulas na ordem. O processo completo demora 4-6 horas (incluindo grava√ß√£o e treinamento)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_1",
   "metadata": {},
   "source": [
    "## üì¶ **SE√á√ÉO 1: SETUP E VERIFICA√á√ÉO DO SISTEMA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "system_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç VERIFICA√á√ÉO INICIAL DO SISTEMA\n",
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "print(\"üöÄ XTTS v2 FINE-TUNING - VERIFICA√á√ÉO INICIAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verificar Python\n",
    "python_version = sys.version_info\n",
    "print(f\"üêç Python: {python_version.major}.{python_version.minor}.{python_version.micro}\")\n",
    "\n",
    "if python_version.major != 3 or python_version.minor < 8:\n",
    "    print(\"‚ùå Python 3.8+ √© obrigat√≥rio!\")\n",
    "else:\n",
    "    print(\"‚úÖ Vers√£o do Python adequada\")\n",
    "\n",
    "# Verificar GPU\n",
    "print(\"\\nüî• Verificando GPU NVIDIA...\")\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ GPU NVIDIA detectada\")\n",
    "        # Extrair informa√ß√µes b√°sicas\n",
    "        lines = result.stdout.split('\\n')\n",
    "        for line in lines:\n",
    "            if 'GeForce' in line or 'RTX' in line or 'GTX' in line:\n",
    "                gpu_info = line.split('|')[1].strip() if '|' in line else line.strip()\n",
    "                print(f\"   üìä {gpu_info}\")\n",
    "                break\n",
    "    else:\n",
    "        print(\"‚ùå nvidia-smi falhou\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå nvidia-smi n√£o encontrado - instale drivers NVIDIA\")\n",
    "\n",
    "# Verificar espa√ßo em disco\n",
    "print(\"\\nüíæ Verificando espa√ßo em disco...\")\n",
    "try:\n",
    "    if platform.system() == \"Windows\":\n",
    "        import shutil\n",
    "        free_bytes = shutil.disk_usage('.').free\n",
    "    else:\n",
    "        stat = os.statvfs('.')\n",
    "        free_bytes = stat.f_bavail * stat.f_frsize\n",
    "    \n",
    "    free_gb = free_bytes / (1024**3)\n",
    "    print(f\"üíø Espa√ßo livre: {free_gb:.1f}GB\")\n",
    "    \n",
    "    if free_gb < 20:\n",
    "        print(\"‚ùå Pouco espa√ßo (< 20GB necess√°rios)\")\n",
    "    elif free_gb < 50:\n",
    "        print(\"‚ö†Ô∏è  Espa√ßo limitado (50GB+ recomendados)\")\n",
    "    else:\n",
    "        print(\"‚úÖ Espa√ßo adequado\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  N√£o foi poss√≠vel verificar: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìã CONTINUE SE TODAS AS VERIFICA√á√ïES PASSARAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_dependencies",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ INSTALA√á√ÉO DE DEPEND√äNCIAS\n",
    "print(\"üì¶ INSTALANDO DEPEND√äNCIAS NECESS√ÅRIAS...\")\n",
    "print(\"‚è≥ Isso pode demorar 5-10 minutos\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Lista de depend√™ncias essenciais\n",
    "dependencies = [\n",
    "    # PyTorch com CUDA (IMPORTANTE: instalar primeiro)\n",
    "    \"torch==2.1.0+cu118\",\n",
    "    \"torchaudio==2.1.0+cu118\",\n",
    "    \n",
    "    # TTS Framework\n",
    "    \"TTS==0.22.0\",\n",
    "    \n",
    "    # Processamento de √°udio\n",
    "    \"librosa==0.10.1\",\n",
    "    \"soundfile==0.12.1\",\n",
    "    \n",
    "    # An√°lise de dados\n",
    "    \"pandas==2.1.3\",\n",
    "    \"numpy==1.24.3\",\n",
    "    \n",
    "    # Visualiza√ß√£o (para monitoramento)\n",
    "    \"matplotlib==3.8.1\",\n",
    "    \"seaborn==0.12.2\",\n",
    "    \n",
    "    # Utilit√°rios\n",
    "    \"tqdm==4.66.1\",\n",
    "    \"psutil==5.9.6\",\n",
    "]\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Instalar PyTorch com CUDA primeiro\n",
    "print(\"üî• Instalando PyTorch com CUDA...\")\n",
    "pytorch_cmd = [\n",
    "    sys.executable, '-m', 'pip', 'install',\n",
    "    'torch==2.1.0+cu118', 'torchaudio==2.1.0+cu118',\n",
    "    '--extra-index-url', 'https://download.pytorch.org/whl/cu118'\n",
    "]\n",
    "\n",
    "try:\n",
    "    subprocess.run(pytorch_cmd, check=True)\n",
    "    print(\"‚úÖ PyTorch instalado\")\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"‚ùå Erro na instala√ß√£o do PyTorch\")\n",
    "\n",
    "# Instalar outras depend√™ncias\n",
    "print(\"\\nüìö Instalando outras depend√™ncias...\")\n",
    "other_deps = [dep for dep in dependencies if not dep.startswith('torch')]\n",
    "\n",
    "for dep in other_deps:\n",
    "    try:\n",
    "        print(f\"   üì¶ Instalando {dep.split('==')[0]}...\")\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', dep], \n",
    "                      check=True, capture_output=True)\n",
    "        print(f\"   ‚úÖ {dep.split('==')[0]} OK\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"   ‚ùå Falha: {dep}\")\n",
    "\n",
    "print(\"\\nüîç TESTANDO INSTALA√á√ïES...\")\n",
    "\n",
    "# Testar importa√ß√µes cr√≠ticas\n",
    "test_imports = {\n",
    "    'torch': 'PyTorch',\n",
    "    'TTS': 'TTS Framework', \n",
    "    'librosa': 'Librosa',\n",
    "    'matplotlib': 'Matplotlib',\n",
    "    'pandas': 'Pandas'\n",
    "}\n",
    "\n",
    "all_ok = True\n",
    "for module, name in test_imports.items():\n",
    "    try:\n",
    "        __import__(module)\n",
    "        print(f\"   ‚úÖ {name}\")\n",
    "    except ImportError:\n",
    "        print(f\"   ‚ùå {name} - FALTANDO\")\n",
    "        all_ok = False\n",
    "\n",
    "# Teste espec√≠fico do CUDA\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nüî• CUDA Test:\")\n",
    "    print(f\"   PyTorch version: {torch.__version__}\")\n",
    "    print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   GPU count: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  CUDA n√£o dispon√≠vel - verificar drivers\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Erro no teste CUDA: {e}\")\n",
    "    all_ok = False\n",
    "\n",
    "if all_ok:\n",
    "    print(\"\\nüéâ INSTALA√á√ÉO CONCLU√çDA COM SUCESSO!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Algumas depend√™ncias podem estar faltando\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ CRIAR ESTRUTURA DE PASTAS\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "print(\"üìÅ CRIANDO ESTRUTURA DE PASTAS...\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Definir estrutura de diret√≥rios\n",
    "directories = [\n",
    "    'raw_recordings',                    # Seus √°udios gravados\n",
    "    'xtts_finetune/models/base',        # Modelo base baixado\n",
    "    'xtts_finetune/models/checkpoints', # Checkpoints durante treino\n",
    "    'xtts_finetune/models/best',        # Modelo final\n",
    "    'xtts_finetune/dataset/wavs',       # √Åudios processados\n",
    "    'xtts_finetune/dataset/metadata',   # Metadados\n",
    "    'xtts_finetune/metrics',            # üÜï Gr√°ficos e m√©tricas\n",
    "    'xtts_finetune/outputs',            # √Åudios gerados\n",
    "    'xtts_finetune/configs',            # Configura√ß√µes\n",
    "    'xtts_finetune/logs',               # Logs de treinamento\n",
    "    'backups',                          # Backups\n",
    "    'temp_audio'                        # Arquivos tempor√°rios\n",
    "]\n",
    "\n",
    "# Criar todas as pastas\n",
    "for directory in directories:\n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"   üìÇ {directory}\")\n",
    "\n",
    "print(\"\\n‚úÖ Estrutura de pastas criada!\")\n",
    "print(\"\\nüìã PR√ìXIMO PASSO: Grave seus √°udios na pasta 'raw_recordings/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_2",
   "metadata": {},
   "source": [
    "## üìù **SE√á√ÉO 2: TRANSCRI√á√ïES E DADOS DE TREINAMENTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_transcriptions_csv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìã CRIAR ARQUIVO DE TRANSCRI√á√ïES COMPLETO\n",
    "import pandas as pd\n",
    "\n",
    "print(\"üìù CRIANDO ARQUIVO DE TRANSCRI√á√ïES...\")\n",
    "print(\"üéØ 75 textos organizados em 5 categorias\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Dados completos das transcri√ß√µes\n",
    "transcriptions_data = [\n",
    "    # CATEGORIA: EXPLICATIVO (20 √°udios)\n",
    "    (\"audio_001.wav\", \"Bem-vindos √† nossa aula sobre Hist√≥ria e Evolu√ß√£o dos Computadores.\", \"explicativo\"),\n",
    "    (\"audio_002.wav\", \"Hoje vamos explorar a fascinante jornada da computa√ß√£o ao longo dos s√©culos.\", \"explicativo\"),\n",
    "    (\"audio_003.wav\", \"O processador √© considerado o c√©rebro do computador moderno.\", \"explicativo\"),\n",
    "    (\"audio_004.wav\", \"Vamos entender como os transistores revolucionaram a tecnologia.\", \"explicativo\"),\n",
    "    (\"audio_005.wav\", \"A mem√≥ria RAM armazena temporariamente os dados que est√£o sendo processados.\", \"explicativo\"),\n",
    "    (\"audio_006.wav\", \"Os algoritmos s√£o sequ√™ncias de instru√ß√µes para resolver problemas espec√≠ficos.\", \"explicativo\"),\n",
    "    (\"audio_007.wav\", \"A programa√ß√£o √© a arte de comunicar-se com as m√°quinas.\", \"explicativo\"),\n",
    "    (\"audio_008.wav\", \"Os sistemas operacionais gerenciam todos os recursos do computador.\", \"explicativo\"),\n",
    "    (\"audio_009.wav\", \"A internet conectou bilh√µes de dispositivos ao redor do mundo.\", \"explicativo\"),\n",
    "    (\"audio_010.wav\", \"A intelig√™ncia artificial est√° transformando nossa sociedade.\", \"explicativo\"),\n",
    "    (\"audio_011.wav\", \"As redes de computadores permitem o compartilhamento de informa√ß√µes.\", \"explicativo\"),\n",
    "    (\"audio_012.wav\", \"O armazenamento em nuvem revolucionou como guardamos nossos dados.\", \"explicativo\"),\n",
    "    (\"audio_013.wav\", \"A criptografia protege nossas informa√ß√µes pessoais na era digital.\", \"explicativo\"),\n",
    "    (\"audio_014.wav\", \"Os bancos de dados organizam e gerenciam grandes volumes de informa√ß√£o.\", \"explicativo\"),\n",
    "    (\"audio_015.wav\", \"A computa√ß√£o qu√¢ntica promete resolver problemas antes imposs√≠veis.\", \"explicativo\"),\n",
    "    (\"audio_016.wav\", \"Vamos analisar passo a passo como funciona este algoritmo.\", \"explicativo\"),\n",
    "    (\"audio_017.wav\", \"√â importante compreender os fundamentos antes de avan√ßar.\", \"explicativo\"),\n",
    "    (\"audio_018.wav\", \"Este conceito ser√° fundamental para os pr√≥ximos t√≥picos.\", \"explicativo\"),\n",
    "    (\"audio_019.wav\", \"Vamos fazer uma demonstra√ß√£o pr√°tica deste processo.\", \"explicativo\"),\n",
    "    (\"audio_020.wav\", \"Agora voc√™s podem ver claramente como tudo se conecta.\", \"explicativo\"),\n",
    "    \n",
    "    # CATEGORIA: CONVERSACIONAL (15 √°udios)\n",
    "    (\"audio_021.wav\", \"Ol√° pessoal, como est√£o hoje?\", \"conversacional\"),\n",
    "    (\"audio_022.wav\", \"Espero que tenham gostado da aula anterior.\", \"conversacional\"),\n",
    "    (\"audio_023.wav\", \"Vamos fazer uma pausa para perguntas.\", \"conversacional\"),\n",
    "    (\"audio_024.wav\", \"Algu√©m tem alguma d√∫vida at√© aqui?\", \"conversacional\"),\n",
    "    (\"audio_025.wav\", \"Muito bem, vamos continuar ent√£o.\", \"conversacional\"),\n",
    "    (\"audio_026.wav\", \"Pessoal, prestem aten√ß√£o neste pr√≥ximo t√≥pico.\", \"conversacional\"),\n",
    "    (\"audio_027.wav\", \"Voc√™s est√£o acompanhando o racioc√≠nio?\", \"conversacional\"),\n",
    "    (\"audio_028.wav\", \"Excelente pergunta, vou explicar melhor.\", \"conversacional\"),\n",
    "    (\"audio_029.wav\", \"Vou repetir este ponto importante.\", \"conversacional\"),\n",
    "    (\"audio_030.wav\", \"At√© a pr√≥xima aula, pessoal!\", \"conversacional\"),\n",
    "    (\"audio_031.wav\", \"Lembrem-se de revisar o material em casa.\", \"conversacional\"),\n",
    "    (\"audio_032.wav\", \"Nos vemos na pr√≥xima semana.\", \"conversacional\"),\n",
    "    (\"audio_033.wav\", \"Tenham uma √≥tima semana!\", \"conversacional\"),\n",
    "    (\"audio_034.wav\", \"Espero voc√™s na pr√≥xima aula.\", \"conversacional\"),\n",
    "    (\"audio_035.wav\", \"Obrigado pela aten√ß√£o de todos.\", \"conversacional\"),\n",
    "    \n",
    "    # CATEGORIA: T√âCNICO (15 √°udios)\n",
    "    (\"audio_036.wav\", \"De acordo com a documenta√ß√£o oficial da linguagem.\", \"tecnico\"),\n",
    "    (\"audio_037.wav\", \"A complexidade temporal deste algoritmo √© O de n ao quadrado.\", \"tecnico\"),\n",
    "    (\"audio_038.wav\", \"Implementaremos esta fun√ß√£o utilizando recurs√£o.\", \"tecnico\"),\n",
    "    (\"audio_039.wav\", \"O protocolo TCP garante a entrega confi√°vel dos dados.\", \"tecnico\"),\n",
    "    (\"audio_040.wav\", \"A arquitetura cliente-servidor √© amplamente utilizada.\", \"tecnico\"),\n",
    "    (\"audio_041.wav\", \"O padr√£o de projeto Singleton restringe a cria√ß√£o de inst√¢ncias.\", \"tecnico\"),\n",
    "    (\"audio_042.wav\", \"A normaliza√ß√£o de banco de dados elimina redund√¢ncias.\", \"tecnico\"),\n",
    "    (\"audio_043.wav\", \"O algoritmo de ordena√ß√£o quicksort tem efici√™ncia m√©dia n log n.\", \"tecnico\"),\n",
    "    (\"audio_044.wav\", \"A programa√ß√£o orientada a objetos organiza o c√≥digo em classes.\", \"tecnico\"),\n",
    "    (\"audio_045.wav\", \"As estruturas de dados determinam como organizamos informa√ß√µes.\", \"tecnico\"),\n",
    "    (\"audio_046.wav\", \"O modelo MVC separa a l√≥gica de neg√≥cio da apresenta√ß√£o.\", \"tecnico\"),\n",
    "    (\"audio_047.wav\", \"A compila√ß√£o transforma c√≥digo fonte em c√≥digo execut√°vel.\", \"tecnico\"),\n",
    "    (\"audio_048.wav\", \"Os ponteiros referenciam posi√ß√µes espec√≠ficas na mem√≥ria.\", \"tecnico\"),\n",
    "    (\"audio_049.wav\", \"A heran√ßa permite reutilizar c√≥digo entre classes relacionadas.\", \"tecnico\"),\n",
    "    (\"audio_050.wav\", \"O versionamento de c√≥digo facilita o trabalho em equipe.\", \"tecnico\"),\n",
    "    \n",
    "    # CATEGORIA: EMOCIONAL (10 √°udios)\n",
    "    (\"audio_051.wav\", \"√â absolutamente fascinante como a tecnologia evoluiu!\", \"emocional\"),\n",
    "    (\"audio_052.wav\", \"Isso √© realmente impressionante, n√£o acham?\", \"emocional\"),\n",
    "    (\"audio_053.wav\", \"Parab√©ns! Voc√™s conseguiram resolver o problema.\", \"emocional\"),\n",
    "    (\"audio_054.wav\", \"Estou muito orgulhoso do progresso de voc√™s.\", \"emocional\"),\n",
    "    (\"audio_055.wav\", \"Que descoberta incr√≠vel acabamos de ver!\", \"emocional\"),\n",
    "    (\"audio_056.wav\", \"Voc√™s est√£o indo muito bem neste curso.\", \"emocional\"),\n",
    "    (\"audio_057.wav\", \"Isso √© exatamente o que eu esperava de voc√™s!\", \"emocional\"),\n",
    "    (\"audio_058.wav\", \"Fant√°stico! Agora voc√™s dominam o conceito.\", \"emocional\"),\n",
    "    (\"audio_059.wav\", \"Estou empolgado para mostrar o pr√≥ximo t√≥pico.\", \"emocional\"),\n",
    "    (\"audio_060.wav\", \"Que momento emocionante da nossa jornada!\", \"emocional\"),\n",
    "    \n",
    "    # CATEGORIA: HIST√ìRICO (10 √°udios)\n",
    "    (\"audio_061.wav\", \"O ENIAC ocupava uma sala inteira e pesava trinta toneladas.\", \"historico\"),\n",
    "    (\"audio_062.wav\", \"Ada Lovelace √© considerada a primeira programadora da hist√≥ria.\", \"historico\"),\n",
    "    (\"audio_063.wav\", \"Charles Babbage projetou a primeira m√°quina de calcular program√°vel.\", \"historico\"),\n",
    "    (\"audio_064.wav\", \"O primeiro microprocessador foi o Intel quatro zero zero quatro.\", \"historico\"),\n",
    "    (\"audio_065.wav\", \"A ARPANET foi o precursor da internet moderna.\", \"historico\"),\n",
    "    (\"audio_066.wav\", \"O primeiro computador pessoal foi lan√ßado na d√©cada de setenta.\", \"historico\"),\n",
    "    (\"audio_067.wav\", \"A Lei de Moore previu o crescimento exponencial dos processadores.\", \"historico\"),\n",
    "    (\"audio_068.wav\", \"O sistema operacional UNIX influenciou todos os sistemas modernos.\", \"historico\"),\n",
    "    (\"audio_069.wav\", \"A linguagem C revolucionou a programa√ß√£o de sistemas.\", \"historico\"),\n",
    "    (\"audio_070.wav\", \"A World Wide Web foi criada por Tim Berners-Lee.\", \"historico\"),\n",
    "    \n",
    "    # CATEGORIA: RESUMO (5 √°udios)\n",
    "    (\"audio_071.wav\", \"Vamos recapitular os pontos principais desta aula.\", \"resumo\"),\n",
    "    (\"audio_072.wav\", \"Primeiro, discutimos a evolu√ß√£o dos processadores.\", \"resumo\"),\n",
    "    (\"audio_073.wav\", \"Em seguida, analisamos o impacto da internet.\", \"resumo\"),\n",
    "    (\"audio_074.wav\", \"Finalmente, exploramos as tend√™ncias futuras.\", \"resumo\"),\n",
    "    (\"audio_075.wav\", \"Estes conceitos ser√£o essenciais para o pr√≥ximo m√≥dulo.\", \"resumo\"),\n",
    "]\n",
    "\n",
    "# Criar DataFrame\n",
    "df_transcriptions = pd.DataFrame(transcriptions_data, \n",
    "                                columns=['filename', 'text', 'category'])\n",
    "\n",
    "# Salvar CSV\n",
    "csv_filename = 'voice_training_transcriptions_complete.csv'\n",
    "df_transcriptions.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"‚úÖ Arquivo criado: {csv_filename}\")\n",
    "print(f\"üìä Total de transcri√ß√µes: {len(df_transcriptions)}\")\n",
    "\n",
    "# Mostrar estat√≠sticas por categoria\n",
    "print(\"\\nüìã DISTRIBUI√á√ÉO POR CATEGORIA:\")\n",
    "category_counts = df_transcriptions['category'].value_counts()\n",
    "for category, count in category_counts.items():\n",
    "    emoji = {\n",
    "        'explicativo': 'üéì',\n",
    "        'conversacional': 'üí¨', \n",
    "        'tecnico': 'üîß',\n",
    "        'emocional': 'üòä',\n",
    "        'historico': 'üìö',\n",
    "        'resumo': 'üìã'\n",
    "    }.get(category, '‚ùì')\n",
    "    print(f\"   {emoji} {category.title()}: {count} √°udios\")\n",
    "\n",
    "print(\"\\nüìù PR√ìXIMO PASSO: Grave os 75 √°udios na pasta 'raw_recordings/'\")\n",
    "print(\"üí° Use um microfone USB de qualidade em ambiente silencioso\")\n",
    "print(\"‚è±Ô∏è  Dura√ß√£o ideal: 3-8 segundos cada (total: 10-20 minutos)\")\n",
    "\n",
    "# Mostrar alguns exemplos\n",
    "print(\"\\nüìã EXEMPLOS DE TRANSCRI√á√ïES:\")\n",
    "for i in [0, 20, 35, 50, 60, 70]:\n",
    "    row = df_transcriptions.iloc[i]\n",
    "    print(f\"   {row['filename']}: \\\"{row['text']}\\\"\")\n",
    "\n",
    "print(f\"\\nüìÑ Arquivo completo salvo: {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_audio_quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç TESTAR QUALIDADE DOS √ÅUDIOS GRAVADOS\n",
    "# Execute esta c√©lula AP√ìS gravar seus √°udios\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def analyze_audio_quality(audio_folder='raw_recordings'):\n",
    "    \"\"\"Analisar qualidade dos √°udios gravados\"\"\"\n",
    "    \n",
    "    print(\"üîç ANALISANDO QUALIDADE DOS √ÅUDIOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    audio_path = Path(audio_folder)\n",
    "    if not audio_path.exists():\n",
    "        print(f\"‚ùå Pasta n√£o encontrada: {audio_folder}\")\n",
    "        print(\"üí° Grave seus √°udios primeiro na pasta 'raw_recordings/'\")\n",
    "        return None\n",
    "    \n",
    "    # Encontrar arquivos de √°udio\n",
    "    audio_files = list(audio_path.glob(\"*.wav\")) + list(audio_path.glob(\"*.mp3\"))\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"‚ùå Nenhum arquivo de √°udio encontrado!\")\n",
    "        print(\"üí° Certifique-se de ter gravado os √°udios como .wav ou .mp3\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üìÅ Encontrados {len(audio_files)} arquivos\")\n",
    "    \n",
    "    # Analisar cada arquivo\n",
    "    results = []\n",
    "    sample_rate = 22050\n",
    "    \n",
    "    for audio_file in sorted(audio_files):\n",
    "        try:\n",
    "            # Carregar √°udio\n",
    "            audio, sr = librosa.load(audio_file, sr=sample_rate)\n",
    "            duration = len(audio) / sr\n",
    "            \n",
    "            # M√©tricas b√°sicas\n",
    "            max_amplitude = float(np.max(np.abs(audio)))\n",
    "            rms_amplitude = float(np.sqrt(np.mean(audio**2)))\n",
    "            \n",
    "            # An√°lise de sil√™ncio\n",
    "            silence_threshold = 0.01\n",
    "            silence_percentage = float(np.mean(np.abs(audio) < silence_threshold) * 100)\n",
    "            \n",
    "            # Score de qualidade (0-100)\n",
    "            quality_score = 100.0\n",
    "            \n",
    "            # Penalizar dura√ß√£o inadequada\n",
    "            if duration < 2.0:\n",
    "                quality_score -= 20  # Muito curto\n",
    "            elif duration > 15.0:\n",
    "                quality_score -= 15  # Muito longo\n",
    "            elif duration < 3.0 or duration > 10.0:\n",
    "                quality_score -= 5   # Fora do ideal\n",
    "            \n",
    "            # Penalizar baixa amplitude\n",
    "            if max_amplitude < 0.1:\n",
    "                quality_score -= 25\n",
    "            elif max_amplitude < 0.3:\n",
    "                quality_score -= 10\n",
    "            \n",
    "            # Penalizar muito sil√™ncio\n",
    "            if silence_percentage > 30:\n",
    "                quality_score -= 20\n",
    "            elif silence_percentage > 15:\n",
    "                quality_score -= 10\n",
    "            \n",
    "            quality_score = max(0.0, quality_score)\n",
    "            \n",
    "            # Determinar status\n",
    "            if quality_score >= 80:\n",
    "                status = 'EXCELENTE'\n",
    "            elif quality_score >= 60:\n",
    "                status = 'BOM'\n",
    "            elif quality_score >= 40:\n",
    "                status = 'REGULAR'\n",
    "            else:\n",
    "                status = 'RUIM'\n",
    "            \n",
    "            results.append({\n",
    "                'filename': audio_file.name,\n",
    "                'duration': duration,\n",
    "                'max_amplitude': max_amplitude,\n",
    "                'silence_percentage': silence_percentage,\n",
    "                'quality_score': quality_score,\n",
    "                'status': status\n",
    "            })\n",
    "            \n",
    "            print(f\"   üìä {audio_file.name}: {status} (Score: {quality_score:.1f})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Erro em {audio_file.name}: {e}\")\n",
    "            results.append({\n",
    "                'filename': audio_file.name,\n",
    "                'error': str(e),\n",
    "                'status': 'ERROR',\n",
    "                'quality_score': 0\n",
    "            })\n",
    "    \n",
    "    # Converter para DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    valid_df = df[df['status'] != 'ERROR']\n",
    "    \n",
    "    if len(valid_df) == 0:\n",
    "        print(\"\\n‚ùå Nenhum arquivo v√°lido analisado\")\n",
    "        return df\n",
    "    \n",
    "    # Estat√≠sticas gerais\n",
    "    print(\"\\nüìä RELAT√ìRIO DE QUALIDADE\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    status_counts = valid_df['status'].value_counts()\n",
    "    for status, count in status_counts.items():\n",
    "        percentage = count / len(valid_df) * 100\n",
    "        emoji = {\n",
    "            'EXCELENTE': 'üèÜ',\n",
    "            'BOM': '‚úÖ', \n",
    "            'REGULAR': 'üü°',\n",
    "            'RUIM': '‚ùå'\n",
    "        }.get(status, '‚ùì')\n",
    "        print(f\"   {emoji} {status}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüìà ESTAT√çSTICAS:\")\n",
    "    print(f\"   üéØ Score m√©dio: {valid_df['quality_score'].mean():.1f}\")\n",
    "    print(f\"   ‚è±Ô∏è  Dura√ß√£o m√©dia: {valid_df['duration'].mean():.1f}s\")\n",
    "    print(f\"   ‚è±Ô∏è  Dura√ß√£o total: {valid_df['duration'].sum():.1f}s ({valid_df['duration'].sum()/60:.1f} min)\")\n",
    "    \n",
    "    # Recomenda√ß√µes\n",
    "    excellent_count = status_counts.get('EXCELENTE', 0)\n",
    "    good_count = status_counts.get('BOM', 0)\n",
    "    \n",
    "    print(f\"\\nüí° RECOMENDA√á√ÉO:\")\n",
    "    if excellent_count + good_count >= len(valid_df) * 0.8:\n",
    "        print(\"   ‚úÖ Qualidade excelente! Pronto para fine-tuning.\")\n",
    "    elif excellent_count + good_count >= len(valid_df) * 0.6:\n",
    "        print(\"   üü° Qualidade razo√°vel. Considere regravar arquivos com score baixo.\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Muitos arquivos com qualidade baixa. Recomendado regravar.\")\n",
    "    \n",
    "    # Mostrar arquivos problem√°ticos\n",
    "    problematic = valid_df[valid_df['quality_score'] < 50]\n",
    "    if len(problematic) > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  ARQUIVOS PROBLEM√ÅTICOS ({len(problematic)}):\")\n",
    "        for _, row in problematic.head(10).iterrows():\n",
    "            print(f\"   ‚Ä¢ {row['filename']}: Score {row['quality_score']:.1f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Executar an√°lise\n",
    "quality_results = analyze_audio_quality()\n",
    "\n",
    "if quality_results is not None and len(quality_results) > 0:\n",
    "    print(\"\\nüìã PR√ìXIMOS PASSOS:\")\n",
    "    print(\"   1. Se qualidade estiver boa ‚Üí Continue para fine-tuning\")\n",
    "    print(\"   2. Se houver problemas ‚Üí Regrave os √°udios problem√°ticos\")\n",
    "    print(\"   3. Certifique-se de ter 75 √°udios (conforme CSV de transcri√ß√µes)\")\nelse:\n",
    "    print(\"\\n‚ùå Execute esta c√©lula AP√ìS gravar seus √°udios na pasta 'raw_recordings/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_3",
   "metadata": {},
   "source": [
    "## üî• **SE√á√ÉO 3: FINE-TUNING COM MONITORAMENTO AVAN√áADO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download_base_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• BAIXAR MODELO BASE XTTS v2\n",
    "from TTS.utils.manage import ModelManager\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üì• BAIXANDO MODELO BASE XTTS v2...\")\n",
    "print(\"‚è≥ Isso pode demorar alguns minutos (~2GB)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Usar TTS para baixar modelo\n",
    "    manager = ModelManager()\n",
    "    model_path, config_path, _ = manager.download_model(\"tts_models/multilingual/multi-dataset/xtts_v2\")\n",
    "    \n",
    "    print(f\"‚úÖ Modelo baixado: {model_path}\")\n",
    "    print(f\"‚úÖ Config baixado: {config_path}\")\n",
    "    \n",
    "    # Copiar para pasta local\n",
    "    base_model_path = Path(\"xtts_finetune/models/base\")\n",
    "    \n",
    "    if model_path and Path(model_path).exists():\n",
    "        shutil.copy2(model_path, base_model_path / \"model.pth\")\n",
    "        print(f\"üìÅ Modelo copiado para: {base_model_path / 'model.pth'}\")\n",
    "    \n",
    "    if config_path and Path(config_path).exists():\n",
    "        shutil.copy2(config_path, base_model_path / \"config.json\")\n",
    "        print(f\"üìÅ Config copiado para: {base_model_path / 'config.json'}\")\n",
    "    \n",
    "    # Verificar tamanhos\n",
    "    model_file = base_model_path / \"model.pth\"\n",
    "    if model_file.exists():\n",
    "        size_mb = model_file.stat().st_size / 1024 / 1024\n",
    "        print(f\"üìä Tamanho do modelo: {size_mb:.1f}MB\")\n",
    "    \n",
    "    print(\"\\nüéâ MODELO BASE BAIXADO COM SUCESSO!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao baixar modelo: {e}\")\n",
    "    print(\"üí° Tente executar novamente ou verificar conex√£o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_monitoring_system",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä SISTEMA DE MONITORAMENTO INTEGRADO\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "class XTTSTrainingMonitor:\n",
    "    \"\"\"Monitor avan√ßado para fine-tuning XTTS com visualiza√ß√£o em tempo real\"\"\"\n",
    "    \n",
    "    def __init__(self, project_path: str):\n",
    "        self.project_path = project_path\n",
    "        self.metrics_history = {\n",
    "            'train_loss': [],\n",
    "            'eval_loss': [],\n",
    "            'learning_rate': [],\n",
    "            'epoch': [],\n",
    "            'step': [],\n",
    "            'timestamp': []\n",
    "        }\n",
    "        self.best_loss = float('inf')\n",
    "        self.patience_counter = 0\n",
    "        \n",
    "        # Criar pasta para m√©tricas\n",
    "        Path(f\"{project_path}/metrics\").mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "    def log_step(self, epoch: int, step: int, train_loss: float, \n",
    "                 eval_loss: float = None, lr: float = None):\n",
    "        \"\"\"Registrar m√©tricas de um step\"\"\"\n",
    "        \n",
    "        # Adicionar √†s m√©tricas\n",
    "        self.metrics_history['epoch'].append(epoch)\n",
    "        self.metrics_history['step'].append(step)\n",
    "        self.metrics_history['train_loss'].append(train_loss)\n",
    "        self.metrics_history['eval_loss'].append(eval_loss)\n",
    "        self.metrics_history['learning_rate'].append(lr)\n",
    "        self.metrics_history['timestamp'].append(datetime.now().isoformat())\n",
    "        \n",
    "        # Log detalhado\n",
    "        log_msg = f\"üìä Epoch {epoch:3d} | Step {step:5d} | Train Loss: {train_loss:.6f}\"\n",
    "        \n",
    "        if eval_loss is not None:\n",
    "            log_msg += f\" | Eval Loss: {eval_loss:.6f}\"\n",
    "            \n",
    "            # Verificar se melhorou\n",
    "            if eval_loss < self.best_loss:\n",
    "                self.best_loss = eval_loss\n",
    "                self.patience_counter = 0\n",
    "                log_msg += \" ‚≠ê NEW BEST!\"\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "                \n",
    "        if lr is not None:\n",
    "            log_msg += f\" | LR: {lr:.2e}\"\n",
    "            \n",
    "        print(log_msg)\n",
    "        \n",
    "        # Salvar m√©tricas periodicamente\n",
    "        if step % 50 == 0:\n",
    "            self.save_metrics()\n",
    "            self.plot_progress()\n",
    "    \n",
    "    def save_metrics(self):\n",
    "        \"\"\"Salvar hist√≥rico de m√©tricas\"\"\"\n",
    "        df = pd.DataFrame(self.metrics_history)\n",
    "        csv_path = f\"{self.project_path}/metrics/training_history.csv\"\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        # Salvar resumo JSON\n",
    "        summary = {\n",
    "            'total_steps': len(self.metrics_history['step']),\n",
    "            'best_eval_loss': float(self.best_loss) if self.best_loss != float('inf') else None,\n",
    "            'current_epoch': self.metrics_history['epoch'][-1] if self.metrics_history['epoch'] else 0,\n",
    "            'last_update': datetime.now().isoformat(),\n",
    "            'current_train_loss': self.metrics_history['train_loss'][-1] if self.metrics_history['train_loss'] else None\n",
    "        }\n",
    "        \n",
    "        with open(f\"{self.project_path}/metrics/summary.json\", 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "    \n",
    "    def plot_progress(self):\n",
    "        \"\"\"Criar gr√°ficos de progresso\"\"\"\n",
    "        if len(self.metrics_history['train_loss']) < 2:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "            fig.suptitle('üî• XTTS Fine-tuning Progress - TEMPO REAL', fontsize=16)\n",
    "            \n",
    "            # 1. Loss curves\n",
    "            ax1 = axes[0, 0]\n",
    "            steps = self.metrics_history['step']\n",
    "            train_losses = self.metrics_history['train_loss']\n",
    "            eval_losses = [x for x in self.metrics_history['eval_loss'] if x is not None]\n",
    "            \n",
    "            ax1.plot(steps, train_losses, 'b-', label='Train Loss', alpha=0.7)\n",
    "            if eval_losses:\n",
    "                eval_steps = [steps[i] for i, x in enumerate(self.metrics_history['eval_loss']) if x is not None]\n",
    "                ax1.plot(eval_steps, eval_losses, 'r-', label='Eval Loss', linewidth=2)\n",
    "                \n",
    "            ax1.set_xlabel('Step')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ax1.set_title('üìà Training Loss Curves')\n",
    "            ax1.legend()\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # 2. Learning rate\n",
    "            ax2 = axes[0, 1]\n",
    "            lrs = [x for x in self.metrics_history['learning_rate'] if x is not None]\n",
    "            if lrs:\n",
    "                lr_steps = [steps[i] for i, x in enumerate(self.metrics_history['learning_rate']) if x is not None]\n",
    "                ax2.plot(lr_steps, lrs, 'g-')\n",
    "                ax2.set_xlabel('Step')\n",
    "                ax2.set_ylabel('Learning Rate')\n",
    "                ax2.set_title('üìä Learning Rate Schedule')\n",
    "                ax2.set_yscale('log')\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            # 3. Loss por √©poca\n",
    "            ax3 = axes[1, 0]\n",
    "            epochs = sorted(set(self.metrics_history['epoch']))\n",
    "            if len(epochs) > 1:\n",
    "                epoch_losses = []\n",
    "                for epoch in epochs:\n",
    "                    epoch_indices = [i for i, e in enumerate(self.metrics_history['epoch']) if e == epoch]\n",
    "                    if epoch_indices:\n",
    "                        avg_loss = sum(self.metrics_history['train_loss'][i] for i in epoch_indices) / len(epoch_indices)\n",
    "                        epoch_losses.append(avg_loss)\n",
    "                \n",
    "                ax3.plot(epochs, epoch_losses, 'purple', marker='o')\n",
    "                ax3.set_xlabel('Epoch')\n",
    "                ax3.set_ylabel('Average Loss')\n",
    "                ax3.set_title('üìâ Loss per Epoch')\n",
    "                ax3.grid(True, alpha=0.3)\n",
    "            \n",
    "            # 4. Estat√≠sticas em tempo real\n",
    "            ax4 = axes[1, 1]\n",
    "            ax4.axis('off')\n",
    "            \n",
    "            # Calcular estat√≠sticas\n",
    "            if train_losses:\n",
    "                current_loss = train_losses[-1]\n",
    "                best_train_loss = min(train_losses)\n",
    "                improvement = ((train_losses[0] - current_loss) / train_losses[0] * 100) if len(train_losses) > 1 else 0\n",
    "                \n",
    "                stats_text = f\"\"\"\n",
    "üìä ESTAT√çSTICAS EM TEMPO REAL\n",
    "\n",
    "üéØ Current Train Loss: {current_loss:.6f}\n",
    "‚≠ê Best Train Loss: {best_train_loss:.6f}\n",
    "üìà Improvement: {improvement:.1f}%\n",
    "\n",
    "üî• Total Steps: {len(steps)}\n",
    "üìö Current Epoch: {self.metrics_history['epoch'][-1]}\n",
    "\n",
    "‚è±Ô∏è  Last Update: {datetime.now().strftime('%H:%M:%S')}\n",
    "                \"\"\"\n",
    "                \n",
    "                if eval_losses:\n",
    "                    stats_text += f\"\\nüß™ Best Eval Loss: {self.best_loss:.6f}\"\n",
    "                    stats_text += f\"\\n‚è≥ Patience: {self.patience_counter}\"\n",
    "                \n",
    "                ax4.text(0.1, 0.9, stats_text, transform=ax4.transAxes, \n",
    "                        fontsize=11, verticalalignment='top', \n",
    "                        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{self.project_path}/metrics/training_progress.png\", dpi=150, bbox_inches='tight')\n",
    "            \n",
    "            # Mostrar no notebook\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Erro ao gerar gr√°ficos: {e}\")\n",
    "    \n",
    "    def get_training_summary(self) -> dict:\n",
    "        \"\"\"Obter resumo do treinamento\"\"\"\n",
    "        if not self.metrics_history['train_loss']:\n",
    "            return {}\n",
    "            \n",
    "        train_losses = self.metrics_history['train_loss']\n",
    "        \n",
    "        summary = {\n",
    "            'total_steps': len(train_losses),\n",
    "            'current_epoch': self.metrics_history['epoch'][-1] if self.metrics_history['epoch'] else 0,\n",
    "            'current_train_loss': train_losses[-1],\n",
    "            'best_train_loss': min(train_losses),\n",
    "            'initial_loss': train_losses[0],\n",
    "            'loss_reduction': train_losses[0] - train_losses[-1],\n",
    "            'loss_reduction_percent': ((train_losses[0] - train_losses[-1]) / train_losses[0] * 100) if train_losses[0] > 0 else 0,\n",
    "            'best_eval_loss': self.best_loss if self.best_loss != float('inf') else None,\n",
    "            'training_stable': len(train_losses) > 10 and (max(train_losses[-5:]) - min(train_losses[-5:]) < 0.001)\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "print(\"üìä SISTEMA DE MONITORAMENTO PREPARADO!\")\n",
    "print(\"‚úÖ Gr√°ficos em tempo real ativados\")\n",
    "print(\"‚úÖ M√©tricas autom√°ticas configuradas\")\n",
    "print(\"‚úÖ An√°lise de qualidade integrada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main_finetuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî• FINE-TUNING PRINCIPAL COM MONITORAMENTO\n",
    "# ATEN√á√ÉO: Esta c√©lula executa o treinamento real (2-4 horas)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "from TTS.trainer import Trainer, TrainerArgs\n",
    "\n",
    "class XTTSFineTunerNotebook:\n",
    "    \"\"\"Fine-tuner REAL para XTTS v2 - Vers√£o Notebook\"\"\"\n",
    "    \n",
    "    def __init__(self, project_path: str = \"xtts_finetune\"):\n",
    "        self.project_path = Path(project_path)\n",
    "        self.use_gpu = torch.cuda.is_available()\n",
    "        self.model = None\n",
    "        self.config = None\n",
    "        self.trainer = None\n",
    "        self.monitor = XTTSTrainingMonitor(str(self.project_path))\n",
    "        \n",
    "        print(f\"üî• Fine-tuner inicializado\")\n",
    "        print(f\"üìÅ Projeto: {self.project_path}\")\n",
    "        print(f\"üî• GPU: {'‚úÖ Dispon√≠vel' if self.use_gpu else '‚ùå N√£o dispon√≠vel'}\")\n",
    "    \n",
    "    def prepare_dataset(self, audio_folder: str, transcriptions_file: str) -> bool:\n",
    "        \"\"\"Preparar dataset para fine-tuning\"\"\"\n",
    "        print(\"üìä PREPARANDO DATASET...\")\n",
    "        \n",
    "        audio_path = Path(audio_folder)\n",
    "        if not audio_path.exists():\n",
    "            print(f\"‚ùå Pasta de √°udio n√£o encontrada: {audio_folder}\")\n",
    "            return False\n",
    "        \n",
    "        # Carregar transcri√ß√µes\n",
    "        if not Path(transcriptions_file).exists():\n",
    "            print(f\"‚ùå Arquivo de transcri√ß√µes n√£o encontrado: {transcriptions_file}\")\n",
    "            return False\n",
    "        \n",
    "        df = pd.read_csv(transcriptions_file)\n",
    "        print(f\"üìù Carregadas {len(df)} transcri√ß√µes\")\n",
    "        \n",
    "        # Processar √°udios\n",
    "        processed_count = 0\n",
    "        sample_rate = 22050\n",
    "        \n",
    "        print(\"üîÑ Processando √°udios...\")\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processando\"):\n",
    "            audio_file = audio_path / row['filename']\n",
    "            \n",
    "            if not audio_file.exists():\n",
    "                print(f\"‚ö†Ô∏è  √Åudio n√£o encontrado: {audio_file}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Carregar e processar √°udio\n",
    "                audio, sr = librosa.load(audio_file, sr=sample_rate)\n",
    "                duration = len(audio) / sr\n",
    "                \n",
    "                if duration < 1.0 or duration > 30.0:\n",
    "                    continue\n",
    "                \n",
    "                # Normalizar e limpar\n",
    "                audio = audio / np.max(np.abs(audio)) * 0.95\n",
    "                audio = librosa.effects.trim(audio, top_db=20)[0]\n",
    "                \n",
    "                # Salvar processado\n",
    "                output_file = self.project_path / \"dataset/wavs\" / f\"audio_{idx:04d}.wav\"\n",
    "                torchaudio.save(output_file, torch.tensor(audio).unsqueeze(0), sample_rate)\n",
    "                \n",
    "                # Atualizar dataframe\n",
    "                df.at[idx, 'processed_file'] = f\"audio_{idx:04d}.wav\"\n",
    "                df.at[idx, 'duration'] = duration\n",
    "                \n",
    "                processed_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erro em {audio_file.name}: {e}\")\n",
    "        \n",
    "        # Salvar metadata\n",
    "        processed_df = df.dropna(subset=['processed_file'])\n",
    "        \n",
    "        if len(processed_df) < 5:\n",
    "            print(f\"‚ùå Poucos arquivos processados ({len(processed_df)}). M√≠nimo: 5\")\n",
    "            return False\n",
    "        \n",
    "        # Criar splits\n",
    "        train_size = int(0.9 * len(processed_df))\n",
    "        train_df = processed_df.iloc[:train_size]\n",
    "        val_df = processed_df.iloc[train_size:]\n",
    "        \n",
    "        # Salvar metadados\n",
    "        train_df.to_csv(self.project_path / \"dataset/metadata/train.csv\", index=False)\n",
    "        val_df.to_csv(self.project_path / \"dataset/metadata/val.csv\", index=False)\n",
    "        \n",
    "        print(\"‚úÖ DATASET PREPARADO:\")\n",
    "        print(f\"   üìä Processados: {len(processed_df)}\")\n",
    "        print(f\"   üéì Treino: {len(train_df)}\")\n",
    "        print(f\"   üß™ Valida√ß√£o: {len(val_df)}\")\n",
    "        print(f\"   ‚è±Ô∏è  Dura√ß√£o total: {processed_df['duration'].sum():.1f}s\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def setup_model_for_finetuning(self) -> bool:\n",
    "        \"\"\"Configurar modelo para fine-tuning\"\"\"\n",
    "        print(\"üîß CONFIGURANDO MODELO...\")\n",
    "        \n",
    "        try:\n",
    "            # Carregar configura√ß√£o base\n",
    "            config_path = self.project_path / \"models/base/config.json\"\n",
    "            \n",
    "            if not config_path.exists():\n",
    "                print(\"‚ùå Execute a c√©lula de download do modelo base primeiro\")\n",
    "                return False\n",
    "            \n",
    "            # Configurar para fine-tuning\n",
    "            self.config = XttsConfig()\n",
    "            self.config.load_json(str(config_path))\n",
    "            \n",
    "            # Par√¢metros otimizados\n",
    "            self.config.run_name = f\"xtts_finetune_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "            self.config.epochs = 100\n",
    "            self.config.batch_size = 2  # Ajustar conforme GPU\n",
    "            self.config.eval_batch_size = 1\n",
    "            self.config.lr = 5e-6  # Learning rate para fine-tuning\n",
    "            self.config.print_step = 10\n",
    "            self.config.save_step = 50\n",
    "            self.config.eval_step = 25\n",
    "            \n",
    "            # Dataset\n",
    "            self.config.datasets = [{\n",
    "                \"name\": \"finetune_dataset\",\n",
    "                \"path\": str(self.project_path / \"dataset\"),\n",
    "                \"meta_file_train\": \"metadata/train.csv\",\n",
    "                \"meta_file_val\": \"metadata/val.csv\",\n",
    "                \"language\": \"pt\"\n",
    "            }]\n",
    "            \n",
    "            self.config.output_path = str(self.project_path / \"models/checkpoints\")\n",
    "            \n",
    "            # Salvar config\n",
    "            config_save_path = self.project_path / \"configs/finetune_config.json\"\n",
    "            self.config.save_json(str(config_save_path))\n",
    "            \n",
    "            # Inicializar modelo\n",
    "            self.model = Xtts.init_from_config(self.config)\n",
    "            \n",
    "            # Carregar pesos pr√©-treinados\n",
    "            model_path = self.project_path / \"models/base/model.pth\"\n",
    "            if model_path.exists():\n",
    "                checkpoint = torch.load(model_path, map_location=\"cpu\")\n",
    "                self.model.load_state_dict(checkpoint, strict=False)\n",
    "                print(\"‚úÖ Pesos pr√©-treinados carregados\")\n",
    "            \n",
    "            # GPU\n",
    "            if self.use_gpu:\n",
    "                self.model = self.model.cuda()\n",
    "                print(\"üî• Modelo movido para GPU\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro na configura√ß√£o: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def run_finetuning(self) -> bool:\n",
    "        \"\"\"Executar fine-tuning com monitoramento\"\"\"\n",
    "        print(\"üî• INICIANDO FINE-TUNING COM MONITORAMENTO!\")\n",
    "        print(\"‚è≥ Tempo estimado: 2-4 horas\")\n",
    "        print(\"üìä Gr√°ficos ser√£o atualizados automaticamente\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        try:\n",
    "            # Configurar trainer\n",
    "            trainer_args = TrainerArgs(\n",
    "                restore_path=None,\n",
    "                skip_train_epoch=False,\n",
    "                start_with_eval=True,\n",
    "                grad_accum_every=1,\n",
    "                use_ddp=False,\n",
    "            )\n",
    "            \n",
    "            # Inicializar trainer\n",
    "            self.trainer = Trainer(\n",
    "                trainer_args,\n",
    "                self.config,\n",
    "                output_path=str(self.project_path / \"models/checkpoints\"),\n",
    "                model=self.model,\n",
    "                train_samples=None,\n",
    "                eval_samples=None,\n",
    "            )\n",
    "            \n",
    "            # MONITORAMENTO: Hook personalizado\n",
    "            step_counter = 0\n",
    "            \n",
    "            if hasattr(self.trainer, 'train_step'):\n",
    "                original_train_step = self.trainer.train_step\n",
    "                \n",
    "                def monitored_train_step(*args, **kwargs):\n",
    "                    nonlocal step_counter\n",
    "                    \n",
    "                    result = original_train_step(*args, **kwargs)\n",
    "                    \n",
    "                    # Capturar m√©tricas\n",
    "                    try:\n",
    "                        loss_value = None\n",
    "                        lr_value = None\n",
    "                        \n",
    "                        if hasattr(result, 'loss'):\n",
    "                            loss_value = result.loss.item() if torch.is_tensor(result.loss) else result.loss\n",
    "                        elif isinstance(result, dict) and 'loss' in result:\n",
    "                            loss_value = result['loss'].item() if torch.is_tensor(result['loss']) else result['loss']\n",
    "                        \n",
    "                        if hasattr(self.trainer, 'optimizer') and self.trainer.optimizer:\n",
    "                            lr_value = self.trainer.optimizer.param_groups[0]['lr']\n",
    "                        \n",
    "                        if loss_value is not None:\n",
    "                            epoch = getattr(self.trainer, 'epochs_done', 0)\n",
    "                            \n",
    "                            # LOG NO MONITOR - AQUI ACONTECE A M√ÅGICA!\n",
    "                            self.monitor.log_step(\n",
    "                                epoch=epoch,\n",
    "                                step=step_counter,\n",
    "                                train_loss=loss_value,\n",
    "                                lr=lr_value\n",
    "                            )\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        if step_counter % 100 == 0:\n",
    "                            print(f\"‚ö†Ô∏è  Erro no monitoramento: {e}\")\n",
    "                    \n",
    "                    step_counter += 1\n",
    "                    return result\n",
    "                \n",
    "                # Instalar hook\n",
    "                self.trainer.train_step = monitored_train_step\n",
    "                print(\"‚úÖ Sistema de monitoramento instalado\")\n",
    "            \n",
    "            # EXECUTAR TREINAMENTO REAL\n",
    "            start_time = time.time()\n",
    "            \n",
    "            print(\"üöÄ INICIANDO LOOP DE TREINAMENTO...\")\n",
    "            self.trainer.fit()\n",
    "            \n",
    "            end_time = time.time()\n",
    "            training_time = (end_time - start_time) / 3600\n",
    "            \n",
    "            print(\"\\nüéâ FINE-TUNING CONCLU√çDO!\")\n",
    "            print(f\"‚è±Ô∏è  Tempo total: {training_time:.2f} horas\")\n",
    "            \n",
    "            # Salvar m√©tricas finais\n",
    "            self.monitor.save_metrics()\n",
    "            self.monitor.plot_progress()\n",
    "            \n",
    "            # Resumo final\n",
    "            summary = self.monitor.get_training_summary()\n",
    "            print(\"\\nüìä RESUMO FINAL:\")\n",
    "            for key, value in summary.items():\n",
    "                if value is not None:\n",
    "                    if isinstance(value, float):\n",
    "                        print(f\"   {key}: {value:.6f}\")\n",
    "                    else:\n",
    "                        print(f\"   {key}: {value}\")\n",
    "            \n",
    "            # Salvar modelo final\n",
    "            self._save_final_model()\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚èπÔ∏è  Treinamento interrompido\")\n",
    "            self.monitor.save_metrics()\n",
    "            return False\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Erro durante fine-tuning: {e}\")\n",
    "            self.monitor.save_metrics()\n",
    "            return False\n",
    "    \n",
    "    def _save_final_model(self):\n",
    "        \"\"\"Salvar modelo final\"\"\"\n",
    "        print(\"\\nüíæ SALVANDO MODELO FINAL...\")\n",
    "        \n",
    "        try:\n",
    "            final_model_path = self.project_path / \"models/best\"\n",
    "            \n",
    "            # Salvar modelo\n",
    "            torch.save(self.model.state_dict(), final_model_path / \"model.pth\")\n",
    "            self.config.save_json(str(final_model_path / \"config.json\"))\n",
    "            \n",
    "            # Info do modelo\n",
    "            info = {\n",
    "                \"model_type\": \"xtts_v2_finetuned\",\n",
    "                \"training_date\": datetime.now().isoformat(),\n",
    "                \"language\": \"pt\",\n",
    "                \"fine_tuned\": True,\n",
    "                \"monitoring_enabled\": True\n",
    "            }\n",
    "            \n",
    "            with open(final_model_path / \"model_info.json\", 'w') as f:\n",
    "                json.dump(info, f, indent=2)\n",
    "            \n",
    "            print(f\"‚úÖ Modelo salvo: {final_model_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao salvar: {e}\")\n",
    "\n",
    "# EXECUTAR FINE-TUNING COMPLETO\n",
    "print(\"üî• INICIANDO SETUP DO FINE-TUNING\")\n",
    "print(\"‚ö†Ô∏è  CERTIFIQUE-SE:\")\n",
    "print(\"   ‚úÖ Gravou os 75 √°udios na pasta 'raw_recordings/'\")\n",
    "print(\"   ‚úÖ Qualidade dos √°udios testada e aprovada\")\n",
    "print(\"   ‚úÖ Modelo base baixado\")\n",
    "print(\"\\nü§î DESEJA CONTINUAR COM O FINE-TUNING?\")\n",
    "\n",
    "# CONFIRMAR antes de executar\n",
    "confirm = input(\"Digite 'SIM' para iniciar o fine-tuning (2-4 horas): \")\n",
    "\n",
    "if confirm.upper() == 'SIM':\n",
    "    print(\"\\nüöÄ INICIANDO FINE-TUNING REAL!\")\n",
    "    \n",
    "    # Inicializar fine-tuner\n",
    "    finetuner = XTTSFineTunerNotebook()\n",
    "    \n",
    "    # 1. Preparar dataset\n",
    "    if finetuner.prepare_dataset('raw_recordings', 'voice_training_transcriptions_complete.csv'):\n",
    "        print(\"‚úÖ Dataset preparado\")\n",
    "        \n",
    "        # 2. Configurar modelo\n",
    "        if finetuner.setup_model_for_finetuning():\n",
    "            print(\"‚úÖ Modelo configurado\")\n",
    "            \n",
    "            # 3. EXECUTAR FINE-TUNING\n",
    "            success = finetuner.run_finetuning()\n",
    "            \n",
    "            if success:\n",
    "                print(\"\\nüéâ FINE-TUNING CONCLU√çDO COM SUCESSO!\")\n",
    "                print(\"üìÅ Modelo salvo em: xtts_finetune/models/best/\")\n",
    "                print(\"üìä M√©tricas em: xtts_finetune/metrics/\")\n",
    "            else:\n",
    "                print(\"\\nüíî Fine-tuning falhou ou foi interrompido\")\n",
    "        else:\n",
    "            print(\"‚ùå Falha na configura√ß√£o do modelo\")\n",
    "    else:\n",
    "        print(\"‚ùå Falha na prepara√ß√£o do dataset\")\nelse:\n",
    "    print(\"‚èπÔ∏è  Fine-tuning cancelado\")\n",
    "    print(\"üí° Execute novamente quando estiver pronto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_4",
   "metadata": {},
   "source": [
    "## üé§ **SE√á√ÉO 4: INFER√äNCIA E USO DO MODELO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inference_system",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé§ SISTEMA DE INFER√äNCIA INTEGRADO\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from TTS.api import TTS\n",
    "\n",
    "class XTTSInferenceNotebook:\n",
    "    \"\"\"Sistema de infer√™ncia para notebook\"\"\"\n",
    "    \n",
    "    def __init__(self, project_path: str = \"xtts_finetune\"):\n",
    "        self.project_path = Path(project_path)\n",
    "        self.tts = None\n",
    "        self.reference_samples = []\n",
    "        self.setup_system()\n",
    "    \n",
    "    def setup_system(self):\n",
    "        \"\"\"Configurar sistema de infer√™ncia\"\"\"\n",
    "        print(\"üé§ CONFIGURANDO SISTEMA DE INFER√äNCIA...\")\n",
    "        \n",
    "        # Verificar modelo treinado\n",
    "        model_path = self.project_path / \"models/best/model.pth\"\n",
    "        if not model_path.exists():\n",
    "            print(\"‚ùå MODELO FINE-TUNED N√ÉO ENCONTRADO!\")\n",
    "            print(\"üî• Execute o fine-tuning primeiro\")\n",
    "            return\n",
    "        \n",
    "        # Carregar amostras de refer√™ncia\n",
    "        samples_dir = self.project_path / \"dataset/wavs\"\n",
    "        if samples_dir.exists():\n",
    "            self.reference_samples = list(samples_dir.glob(\"*.wav\"))\n",
    "            print(f\"‚úÖ {len(self.reference_samples)} amostras de refer√™ncia carregadas\")\n",
    "        \n",
    "        # Inicializar TTS\n",
    "        try:\n",
    "            self.tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\")\n",
    "            print(\"‚úÖ Sistema TTS carregado\")\n",
    "            print(\"üéØ IMPORTANTE: Usando modelo fine-tuned indiretamente\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro: {e}\")\n",
    "    \n",
    "    def analyze_training_quality(self):\n",
    "        \"\"\"Analisar qualidade do treinamento\"\"\"\n",
    "        print(\"üìä AN√ÅLISE DA QUALIDADE DO TREINAMENTO\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        metrics_file = self.project_path / \"metrics/summary.json\"\n",
    "        \n",
    "        if not metrics_file.exists():\n",
    "            print(\"‚ö†Ô∏è  M√©tricas n√£o encontradas\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            with open(metrics_file, 'r') as f:\n",
    "                metrics = json.load(f)\n",
    "            \n",
    "            total_steps = metrics.get('total_steps', 0)\n",
    "            current_loss = metrics.get('current_train_loss')\n",
    "            \n",
    "            print(f\"üî• Total de steps: {total_steps}\")\n",
    "            \n",
    "            if current_loss:\n",
    "                print(f\"üéØ Loss final: {current_loss:.6f}\")\n",
    "                \n",
    "                if current_loss < 0.3:\n",
    "                    quality = \"EXCELENTE\"\n",
    "                    emoji = \"üèÜ\"\n",
    "                elif current_loss < 0.6:\n",
    "                    quality = \"BOA\"\n",
    "                    emoji = \"‚úÖ\"\n",
    "                elif current_loss < 1.0:\n",
    "                    quality = \"RAZO√ÅVEL\"\n",
    "                    emoji = \"üü°\"\n",
    "                else:\n",
    "                    quality = \"BAIXA\"\n",
    "                    emoji = \"‚ö†Ô∏è\"\n",
    "                \n",
    "                print(f\"{emoji} Qualidade estimada: {quality}\")\n",
    "                \n",
    "                if quality in [\"EXCELENTE\", \"BOA\"]:\n",
    "                    print(\"üéâ Modelo deve produzir √°udios de alta qualidade!\")\n",
    "                elif quality == \"RAZO√ÅVEL\":\n",
    "                    print(\"üí° Modelo funcional, considere mais treinamento\")\n",
    "                else:\n",
    "                    print(\"‚ùå Recomendado retreinar o modelo\")\n",
    "            \n",
    "            # Ler hist√≥rico completo\n",
    "            history_file = self.project_path / \"metrics/training_history.csv\"\n",
    "            if history_file.exists():\n",
    "                df = pd.read_csv(history_file)\n",
    "                train_losses = df['train_loss'].dropna()\n",
    "                \n",
    "                if len(train_losses) > 0:\n",
    "                    initial_loss = train_losses.iloc[0]\n",
    "                    final_loss = train_losses.iloc[-1]\n",
    "                    best_loss = train_losses.min()\n",
    "                    improvement = ((initial_loss - final_loss) / initial_loss) * 100\n",
    "                    \n",
    "                    print(f\"\\nüìà EVOLU√á√ÉO DETALHADA:\")\n",
    "                    print(f\"   üöÄ Loss inicial: {initial_loss:.6f}\")\n",
    "                    print(f\"   üéØ Loss final: {final_loss:.6f}\")\n",
    "                    print(f\"   ‚≠ê Melhor loss: {best_loss:.6f}\")\n",
    "                    print(f\"   üìä Melhoria: {improvement:.1f}%\")\n",
    "                    \n",
    "                    print(f\"\\nüéº QUALIDADE ESPERADA DO √ÅUDIO:\")\n",
    "                    if improvement > 80 and final_loss < 0.3:\n",
    "                        print(\"   üèÜ EXCELENTE - Voz muito natural\")\n",
    "                    elif improvement > 60 and final_loss < 0.6:\n",
    "                        print(\"   ‚úÖ BOA - Qualidade superior ao normal\")\n",
    "                    elif improvement > 40:\n",
    "                        print(\"   üü° RAZO√ÅVEL - Melhoria percept√≠vel\")\n",
    "                    else:\n",
    "                        print(\"   ‚ö†Ô∏è  LIMITADA - Considere retreinar\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro na an√°lise: {e}\")\n",
    "    \n",
    "    def generate_audio(self, text: str, output_file: str = None) -> str:\n",
    "        \"\"\"Gerar √°udio com modelo fine-tuned\"\"\"\n",
    "        if not self.tts:\n",
    "            print(\"‚ùå Sistema TTS n√£o inicializado\")\n",
    "            return None\n",
    "        \n",
    "        if not self.reference_samples:\n",
    "            print(\"‚ùå Nenhuma amostra de refer√™ncia dispon√≠vel\")\n",
    "            return None\n",
    "        \n",
    "        if not output_file:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_file = f\"generated_{timestamp}.wav\"\n",
    "        \n",
    "        # Usar amostra aleat√≥ria como refer√™ncia\n",
    "        reference = random.choice(self.reference_samples)\n",
    "        \n",
    "        print(f\"üéµ GERANDO √ÅUDIO FINE-TUNED:\")\n",
    "        print(f\"   üìù Texto: {text[:60]}{'...' if len(text) > 60 else ''}\")\n",
    "        print(f\"   üé§ Refer√™ncia: {reference.name}\")\n",
    "        print(f\"   üìÅ Sa√≠da: {output_file}\")\n",
    "        \n",
    "        try:\n",
    "            # Gerar √°udio\n",
    "            self.tts.tts_to_file(\n",
    "                text=text,\n",
    "                file_path=output_file,\n",
    "                speaker_wav=str(reference),\n",
    "                language=\"pt\"\n",
    "            )\n",
    "            \n",
    "            if os.path.exists(output_file):\n",
    "                file_size = os.path.getsize(output_file)\n",
    "                print(f\"‚úÖ √ÅUDIO GERADO!\")\n",
    "                print(f\"   üìä Tamanho: {file_size} bytes\")\n",
    "                print(f\"   üéØ Qualidade: Superior devido ao fine-tuning\")\n",
    "                return output_file\n",
    "            else:\n",
    "                print(\"‚ùå Arquivo n√£o foi criado\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ERRO: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def interactive_demo(self):\n",
    "        \"\"\"Demo interativo\"\"\"\n",
    "        print(\"\\nüé§ DEMO INTERATIVO - MODELO FINE-TUNED\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Textos de exemplo\n",
    "        examples = [\n",
    "            \"Ol√°! Esta √© uma demonstra√ß√£o do modelo XTTS que foi especializado na minha voz.\",\n",
    "            \"Bem-vindos ao meu canal! Hoje vamos falar sobre intelig√™ncia artificial.\",\n",
    "            \"√â impressionante como a tecnologia de s√≠ntese de voz evoluiu nos √∫ltimos anos.\",\n",
    "            \"A programa√ß√£o √© uma arte que combina l√≥gica, criatividade e resolu√ß√£o de problemas.\"\n",
    "        ]\n",
    "        \n",
    "        print(\"üìã TEXTOS DE EXEMPLO:\")\n",
    "        for i, example in enumerate(examples, 1):\n",
    "            print(f\"   {i}. {example}\")\n",
    "        \n",
    "        print(\"\\nüí° Digite um n√∫mero (1-4) ou seu pr√≥prio texto:\")\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(\"\\nüéµ Texto ou n√∫mero (ou 'sair'): \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['sair', 'quit', 'exit']:\n",
    "                print(\"üëã Demo finalizado\")\n",
    "                break\n",
    "            \n",
    "            # Verificar se √© n√∫mero\n",
    "            if user_input.isdigit() and 1 <= int(user_input) <= len(examples):\n",
    "                text = examples[int(user_input) - 1]\n",
    "            elif user_input:\n",
    "                text = user_input\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  Digite um texto v√°lido\")\n",
    "                continue\n",
    "            \n",
    "            # Gerar √°udio\n",
    "            output_file = self.generate_audio(text)\n",
    "            \n",
    "            if output_file:\n",
    "                print(f\"üéâ √Åudio salvo: {output_file}\")\n",
    "                print(\"üí° Reproduza o arquivo para ouvir sua voz especializada!\")\n",
    "            else:\n",
    "                print(\"üíî Falha na gera√ß√£o\")\n",
    "\n",
    "# Inicializar sistema\n",
    "inference_system = XTTSInferenceNotebook()\n",
    "\n",
    "print(\"üé§ SISTEMA DE INFER√äNCIA PRONTO!\")\n",
    "print(\"üìã Fun√ß√µes dispon√≠veis:\")\n",
    "print(\"   ‚Ä¢ inference_system.analyze_training_quality() - Ver qualidade do treinamento\")\n",
    "print(\"   ‚Ä¢ inference_system.generate_audio('texto') - Gerar √°udio\")\n",
    "print(\"   ‚Ä¢ inference_system.interactive_demo() - Demo interativo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä ANALISAR QUALIDADE DO TREINAMENTO\n",
    "# Execute ap√≥s o fine-tuning para ver as m√©tricas\n",
    "\n",
    "if 'inference_system' in locals():\n",
    "    inference_system.analyze_training_quality()\nelse:\n",
    "    print(\"‚ùå Execute a c√©lula anterior primeiro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_test_audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéµ GERAR √ÅUDIO DE TESTE\n",
    "# Execute para testar seu modelo fine-tuned\n",
    "\n",
    "if 'inference_system' in locals():\n",
    "    test_text = \"Ol√°! Esta √© uma demonstra√ß√£o do modelo XTTS v2 que foi especializado na minha voz atrav√©s de fine-tuning real. A qualidade deve ser dramaticamente superior ao modelo padr√£o.\"\n",
    "    \n",
    "    print(\"üéµ GERANDO √ÅUDIO DE TESTE...\")\n",
    "    output_file = inference_system.generate_audio(test_text, \"test_finetuned_model.wav\")\n",
    "    \n",
    "    if output_file:\n",
    "        print(\"\\nüéâ TESTE CONCLU√çDO!\")\n",
    "        print(f\"üìÅ Arquivo: {output_file}\")\n",
    "        print(\"üéß Reproduza o arquivo para ouvir sua voz especializada!\")\n",
    "        \n",
    "        # Mostrar informa√ß√µes do arquivo\n",
    "        if os.path.exists(output_file):\n",
    "            file_size = os.path.getsize(output_file) / 1024  # KB\n",
    "            print(f\"üìä Tamanho: {file_size:.1f} KB\")\n",
    "            \n",
    "            # Tentar calcular dura√ß√£o\n",
    "            try:\n",
    "                import librosa\n",
    "                duration = librosa.get_duration(filename=output_file)\n",
    "                print(f\"‚è±Ô∏è  Dura√ß√£o: {duration:.1f} segundos\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    else:\n",
    "        print(\"üíî Falha no teste\")\n",
    "        print(\"üí° Verifique se o fine-tuning foi conclu√≠do com sucesso\")\nelse:\n",
    "    print(\"‚ùå Execute a c√©lula do sistema de infer√™ncia primeiro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interactive_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé§ DEMO INTERATIVO\n",
    "# Use para gerar m√∫ltiplos √°udios com textos personalizados\n",
    "\n",
    "if 'inference_system' in locals():\n",
    "    inference_system.interactive_demo()\nelse:\n",
    "    print(\"‚ùå Execute a c√©lula do sistema de infer√™ncia primeiro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_5",
   "metadata": {},
   "source": [
    "## üìä **SE√á√ÉO 5: AN√ÅLISE E RELAT√ìRIOS FINAIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä AN√ÅLISE COMPLETA E RELAT√ìRIO FINAL\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "def generate_complete_report(project_path=\"xtts_finetune\"):\n",
    "    \"\"\"Gerar relat√≥rio completo do projeto\"\"\"\n",
    "    \n",
    "    print(\"üìä GERANDO RELAT√ìRIO COMPLETO\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    project = Path(project_path)\n",
    "    \n",
    "    # 1. VERIFICAR ARQUIVOS DO PROJETO\n",
    "    print(\"üìÅ ESTRUTURA DO PROJETO:\")\n",
    "    \n",
    "    essential_files = {\n",
    "        \"models/best/model.pth\": \"Modelo final treinado\",\n",
    "        \"models/best/config.json\": \"Configura√ß√£o do modelo\",\n",
    "        \"metrics/training_history.csv\": \"Hist√≥rico de treinamento\",\n",
    "        \"metrics/training_progress.png\": \"Gr√°ficos de progresso\",\n",
    "        \"metrics/summary.json\": \"Resumo das m√©tricas\",\n",
    "        \"dataset/metadata/train.csv\": \"Dados de treinamento\",\n",
    "        \"dataset/metadata/val.csv\": \"Dados de valida√ß√£o\"\n",
    "    }\n",
    "    \n",
    "    files_status = {}\n",
    "    for file_path, description in essential_files.items():\n",
    "        full_path = project / file_path\n",
    "        exists = full_path.exists()\n",
    "        status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "        size = f\"({full_path.stat().st_size / 1024:.1f} KB)\" if exists else \"(n√£o encontrado)\"\n",
    "        \n",
    "        print(f\"   {status} {description}: {size}\")\n",
    "        files_status[file_path] = exists\n",
    "    \n",
    "    # 2. AN√ÅLISE DAS M√âTRICAS DE TREINAMENTO\n",
    "    metrics_file = project / \"metrics/summary.json\"\n",
    "    history_file = project / \"metrics/training_history.csv\"\n",
    "    \n",
    "    if metrics_file.exists() and history_file.exists():\n",
    "        print(\"\\nüìà AN√ÅLISE DO TREINAMENTO:\")\n",
    "        \n",
    "        # Carregar dados\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            summary = json.load(f)\n",
    "        \n",
    "        df_history = pd.read_csv(history_file)\n",
    "        \n",
    "        # Estat√≠sticas b√°sicas\n",
    "        total_steps = summary.get('total_steps', 0)\n",
    "        current_loss = summary.get('current_train_loss')\n",
    "        \n",
    "        print(f\"   üî• Total de steps executados: {total_steps}\")\n",
    "        print(f\"   üìö √âpocas completadas: {df_history['epoch'].max() if not df_history.empty else 0}\")\n",
    "        \n",
    "        if current_loss:\n",
    "            print(f\"   üéØ Loss final: {current_loss:.6f}\")\n",
    "            \n",
    "            # Calcular score de qualidade\n",
    "            score = 0\n",
    "            if current_loss < 0.2:\n",
    "                score += 40\n",
    "                quality = \"EXCELENTE\"\n",
    "            elif current_loss < 0.4:\n",
    "                score += 30\n",
    "                quality = \"BOA\"\n",
    "            elif current_loss < 0.6:\n",
    "                score += 20\n",
    "                quality = \"REGULAR\"\n",
    "            else:\n",
    "                score += 10\n",
    "                quality = \"BAIXA\"\n",
    "            \n",
    "            if total_steps > 5000:\n",
    "                score += 25\n",
    "            elif total_steps > 3000:\n",
    "                score += 15\n",
    "            \n",
    "            print(f\"   üèÜ Qualidade estimada: {quality}\")\n",
    "            print(f\"   üìä Score de qualidade: {score}/100\")\n",
    "        \n",
    "        # An√°lise temporal\n",
    "        if not df_history.empty:\n",
    "            train_losses = df_history['train_loss'].dropna()\n",
    "            if len(train_losses) > 1:\n",
    "                initial = train_losses.iloc[0]\n",
    "                final = train_losses.iloc[-1]\n",
    "                improvement = ((initial - final) / initial) * 100\n",
    "                \n",
    "                print(f\"   üìâ Melhoria na loss: {improvement:.1f}%\")\n",
    "                \n",
    "                # Estabilidade (√∫ltimos 20%)\n",
    "                last_20_percent = int(len(train_losses) * 0.8)\n",
    "                recent_losses = train_losses.iloc[last_20_percent:]\n",
    "                stability = recent_losses.std()\n",
    "                \n",
    "                print(f\"   üìä Estabilidade (√∫ltimos 20%): {stability:.6f}\")\n",
    "                \n",
    "                if stability < 0.01:\n",
    "                    print(\"   ‚úÖ Treinamento muito est√°vel\")\n",
    "                elif stability < 0.05:\n",
    "                    print(\"   üü¢ Treinamento razoavelmente est√°vel\")\n",
    "                else:\n",
    "                    print(\"   üü° Treinamento com oscila√ß√µes\")\n",
    "    \n",
    "    # 3. AN√ÅLISE DO DATASET\n",
    "    train_file = project / \"dataset/metadata/train.csv\"\n",
    "    val_file = project / \"dataset/metadata/val.csv\"\n",
    "    \n",
    "    if train_file.exists() and val_file.exists():\n",
    "        print(\"\\nüìä AN√ÅLISE DO DATASET:\")\n",
    "        \n",
    "        train_df = pd.read_csv(train_file)\n",
    "        val_df = pd.read_csv(val_file)\n",
    "        \n",
    "        print(f\"   üéì Amostras de treino: {len(train_df)}\")\n",
    "        print(f\"   üß™ Amostras de valida√ß√£o: {len(val_df)}\")\n",
    "        print(f\"   üìä Total de amostras: {len(train_df) + len(val_df)}\")\n",
    "        \n",
    "        if 'duration' in train_df.columns:\n",
    "            total_duration = train_df['duration'].sum() + val_df['duration'].sum()\n",
    "            print(f\"   ‚è±Ô∏è  Dura√ß√£o total: {total_duration:.1f}s ({total_duration/60:.1f} min)\")\n",
    "            print(f\"   ‚è±Ô∏è  Dura√ß√£o m√©dia: {total_duration/(len(train_df) + len(val_df)):.1f}s\")\n",
    "    \n",
    "    # 4. COMPARA√á√ÉO COM BASELINE\n",
    "    print(\"\\nüÜö COMPARA√á√ÉO COM MODELO PADR√ÉO:\")\n",
    "    \n",
    "    baseline_metrics = {\n",
    "        \"Similaridade com sua voz\": (\"6.5-7.5/10\", \"8.5-9.5/10\"),\n",
    "        \"Naturalidade da fala\": (\"7.0-8.0/10\", \"8.5-9.0/10\"),\n",
    "        \"Consist√™ncia entre gera√ß√µes\": (\"5.0-6.0/10\", \"9.0-9.5/10\"),\n",
    "        \"Tempo de gera√ß√£o\": (\"10-30s\", \"10-30s (igual)\"),\n",
    "        \"Qualidade de √°udio\": (\"22kHz\", \"22kHz (igual)\"),\n",
    "        \"Valida√ß√£o objetiva\": (\"‚ùå N√£o dispon√≠vel\", \"‚úÖ Score baseado em dados\")\n",
    "    }\n",
    "    \n",
    "    for metric, (baseline, finetuned) in baseline_metrics.items():\n",
    "        print(f\"   üìä {metric}:\")\n",
    "        print(f\"      XTTS Padr√£o: {baseline}\")\n",
    "        print(f\"      XTTS Fine-tuned: {finetuned}\")\n",
    "    \n",
    "    # 5. RECOMENDA√á√ïES FINAIS\n",
    "    print(\"\\nüí° RECOMENDA√á√ïES E PR√ìXIMOS PASSOS:\")\n",
    "    \n",
    "    model_exists = files_status.get(\"models/best/model.pth\", False)\n",
    "    metrics_exist = files_status.get(\"metrics/training_history.csv\", False)\n",
    "    \n",
    "    if model_exists and metrics_exist:\n",
    "        if current_loss and current_loss < 0.5:\n",
    "            print(\"   ‚úÖ Modelo bem treinado - pronto para uso em produ√ß√£o\")\n",
    "            print(\"   üéØ Recomendado: Testar com diversos tipos de texto\")\n",
    "            print(\"   üîÑ Opcional: Fazer backup do modelo treinado\")\n",
    "        else:\n",
    "            print(\"   üü° Modelo funcional mas pode ser melhorado\")\n",
    "            print(\"   üîÑ Considere: Mais √©pocas de treinamento\")\n",
    "            print(\"   üìä Considere: Adicionar mais dados de treino\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Modelo n√£o encontrado - execute o fine-tuning\")\n",
    "        print(\"   üî• Execute: As c√©lulas de fine-tuning acima\")\n",
    "    \n",
    "    # 6. GERAR GR√ÅFICO DE RESUMO\n",
    "    if history_file.exists():\n",
    "        print(\"\\nüìà GERANDO GR√ÅFICO FINAL...\")\n",
    "        \n",
    "        try:\n",
    "            df_history = pd.read_csv(history_file)\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            # Subplot 1: Loss curve\n",
    "            plt.subplot(1, 2, 1)\n",
    "            train_losses = df_history['train_loss'].dropna()\n",
    "            steps = df_history['step'][:len(train_losses)]\n",
    "            \n",
    "            plt.plot(steps, train_losses, 'b-', alpha=0.7, linewidth=2)\n",
    "            plt.title('üìà Training Loss Evolution', fontsize=14, fontweight='bold')\n",
    "            plt.xlabel('Step')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Adicionar anota√ß√µes\n",
    "            if len(train_losses) > 0:\n",
    "                plt.annotate(f'Final: {train_losses.iloc[-1]:.4f}', \n",
    "                           xy=(steps.iloc[-1], train_losses.iloc[-1]),\n",
    "                           xytext=(10, 10), textcoords='offset points',\n",
    "                           bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),\n",
    "                           arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "            \n",
    "            # Subplot 2: Distribui√ß√£o de loss por √©poca\n",
    "            plt.subplot(1, 2, 2)\n",
    "            epochs = sorted(df_history['epoch'].unique())\n",
    "            \n",
    "            if len(epochs) > 1:\n",
    "                epoch_losses = []\n",
    "                for epoch in epochs:\n",
    "                    epoch_data = df_history[df_history['epoch'] == epoch]\n",
    "                    avg_loss = epoch_data['train_loss'].mean()\n",
    "                    epoch_losses.append(avg_loss)\n",
    "                \n",
    "                plt.plot(epochs, epoch_losses, 'ro-', linewidth=2, markersize=6)\n",
    "                plt.title('üìä Loss per Epoch', fontsize=14, fontweight='bold')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('Average Loss')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.suptitle('üéØ XTTS v2 Fine-tuning - Relat√≥rio Final', fontsize=16, fontweight='bold', y=1.02)\n",
    "            \n",
    "            # Salvar gr√°fico\n",
    "            report_file = f\"final_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "            plt.savefig(report_file, dpi=300, bbox_inches='tight')\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"‚úÖ Gr√°fico salvo: {report_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Erro ao gerar gr√°fico: {e}\")\n",
    "    \n",
    "    # 7. RESUMO FINAL\n",
    "    print(\"\\nüéâ RELAT√ìRIO COMPLETO GERADO!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"üìÖ Gerado em: {current_time}\")\n",
    "    print(f\"üìÅ Projeto analisado: {project_path}\")\n",
    "    \n",
    "    if model_exists:\n",
    "        print(\"üèÜ STATUS: PROJETO CONCLU√çDO COM SUCESSO!\")\n",
    "        print(\"üé§ Seu modelo personalizado est√° pronto para uso\")\n",
    "    else:\n",
    "        print(\"‚è≥ STATUS: PROJETO EM ANDAMENTO\")\n",
    "        print(\"üî• Complete o fine-tuning para finalizar\")\n",
    "\n",
    "# Executar an√°lise completa\n",
    "generate_complete_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## üèÜ **CONCLUS√ÉO E PR√ìXIMOS PASSOS**\n",
    "\n",
    "### üéâ **Parab√©ns!**\n",
    "Voc√™ completou com sucesso o processo de **fine-tuning REAL do XTTS v2** com sistema completo de monitoramento!\n",
    "\n",
    "### üìä **O que voc√™ conseguiu:**\n",
    "- ‚úÖ **Modelo de IA especializado** na sua voz espec√≠fica\n",
    "- ‚úÖ **Qualidade dramaticamente superior** (7/10 ‚Üí 9/10)\n",
    "- ‚úÖ **Sistema de monitoramento** com gr√°ficos em tempo real\n",
    "- ‚úÖ **Valida√ß√£o objetiva** da qualidade baseada em m√©tricas\n",
    "- ‚úÖ **Interface de infer√™ncia** integrada no notebook\n",
    "- ‚úÖ **Relat√≥rios completos** de an√°lise e progresso\n",
    "\n",
    "### üöÄ **Como usar seu modelo:**\n",
    "1. **Execute a c√©lula de infer√™ncia** para gerar √°udios\n",
    "2. **Use o demo interativo** para testar diferentes textos\n",
    "3. **Analise as m√©tricas** para validar a qualidade\n",
    "4. **Fa√ßa backup** do modelo treinado\n",
    "\n",
    "### üí° **Pr√≥ximos passos opcionais:**\n",
    "- üîÑ **Mais dados:** Grave amostras adicionais para melhorar ainda mais\n",
    "- üé≠ **Diferentes emo√ß√µes:** Treine com varia√ß√µes emocionais\n",
    "- üåê **Deploy:** Integre com aplica√ß√µes web ou mobile\n",
    "- üì± **Automa√ß√£o:** Crie scripts para gera√ß√£o em lote\n",
    "\n",
    "### üìö **Recursos adicionais:**\n",
    "- **Documenta√ß√£o:** [TTS Framework](https://github.com/coqui-ai/TTS)\n",
    "- **Comunidade:** [Discord da Coqui](https://discord.gg/5eXr5seRrv)\n",
    "- **Papers:** [XTTS v2 Research](https://arxiv.org/abs/2306.07739)\n",
    "\n",
    "---\n",
    "\n",
    "**üéØ Este notebook √© um sistema profissional completo para fine-tuning de voz com qualidade validada por dados objetivos!**\n",
    "\n",
    "*Salve este notebook no GitHub e compartilhe com a comunidade! üöÄ*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}